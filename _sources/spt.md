# Revisiting the Power of Prompt for Visual Tuning
- 文章链接：[http://arxiv.org/abs/2402.02382](http://arxiv.org/abs/2402.02382)
- Github [https://github.com/WangYZ1608/Self-PromptTuning](https://github.com/WangYZ1608/Self-PromptTuning)
- 时间：2024
## 摘要
Visual prompt tuning（VPT）是一种有前景的解决方案，它通过引入可学习的提示符来定制预训练模型以适应下游任务。然而，VPT及其变体常常面临诸如提示符初始化、提示符长度以及在自监督预训练中表现不佳等挑战，这些因素阻碍了成功地进行上下文适应。本研究首先探讨了在熟练训练过程中提示符与图像块标记之间的相关性演变。受观察到提示符与图像块标记之间存在高度互信息的启发，我们提出使用下游标记原型来初始化提示符。这种策略性的初始化，取代了之前的初始化方法，显著提高了性能。为了进一步优化，我们通过一个简化的流程来优化标记构建，与VPT相比，几乎不增加计算成本的同时保持了优异的性能。详尽的实验表明，我们提出的方法在性能上显著优于现有方法。例如，在MAE预训练之后，我们的方法比VPT提高了10%∼30%的准确率，并且在使用的可学习参数不到0.4%的情况下，在24个案例中有19个案例超过了全量微调。此外，实验结果还表明，提出的自提示调整（SPT）对提示符长度具有鲁棒性，并且能够很好地适应模型容量和训练数据规模。最后，我们提供了一个有见地的探索，研究了为目标数据量，以促进预训练模型适应下游任务。

## 模型/方法